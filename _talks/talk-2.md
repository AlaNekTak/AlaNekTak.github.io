---
title: "GPT-4 Emulates Average-Human Emotional Cognition from a Third-Person Perspective"
collection: talks
type: "Talk"
permalink: /talks/talk-2
venue: "2024 12th International Conference on Affective Computing and Intelligent Interaction (ACII)"
date: 2024-09-15
Publisher: "arXiv"
DOI: "https://arxiv.org/abs/2408.13718"
location: "Glasgow, Scotland"
---

This work recent investigations on the emotional reasoning abilities of Large Language Models (LLMs). Current research on LLMs has not directly evaluated the distinction between how LLMs predict the self-attribution of emotions and the perception of others' emotions. We first look at carefully crafted emotion-evoking stimuli, originally designed to find patterns of brain neural activity representing fine-grained inferred emotional attributions of others. We show that GPT-4 is especially accurate in reasoning about such stimuli. This suggests LLMs agree with humans' attributions of others' emotions in stereotypical scenarios remarkably more than self-attributions of emotions in idiosyncratic situations. To further explore this, our second study utilizes a dataset containing annotations from both the author and a third-person perspective. We find that GPT-4's interpretations align more closely with human judgments about the emotions of others than with self-assessments. Notably, conventional computational models of emotion primarily rely on self-reported ground truth as the gold standard. However, an average observer's standpoint, which LLMs appear to have adopted, might be more relevant for many downstream applications, at least in the absence of individual information and adequate safety considerations.
 
<img src="/images/glasgow-acii.jpg" alt="Conference Image2" width="600"/> 


